{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDPwO_sNVZqx",
        "outputId": "8f6bb3d4-509c-477e-8e62-4770491ee3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent-kafka==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent-kafka==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6ED1zWbVd6v",
        "outputId": "eb31b262-91ec-4a42-c7d5-2189f27d737a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.11/dist-packages (5.2.1)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.28)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.11/dist-packages (1.31.1)\n",
            "Requirement already satisfied: google-cloud-spanner in /usr/local/lib/python3.11/dist-packages (3.53.0)\n",
            "Requirement already satisfied: confluent-kafka in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.28 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.28)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.30)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api) (8.6.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (2.4.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.14.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (1.26.1)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.5.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (5.29.4)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.15.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.69.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.71.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api) (3.21.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.70.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (3.11.15)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (2.1.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.6.7)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (2.11.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.9.0)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.17)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.18.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.7.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.9)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.28->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy requests redis neo4j faiss-cpu torch transformers scikit-learn llama-index hdbscan opentelemetry-api google-cloud-spanner confluent-kafka\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBCTJxHmVide",
        "outputId": "4881850a-37c1-4abb-c3e0-38af8d7c1f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.11/dist-packages (5.2.1)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.28)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.11/dist-packages (1.31.1)\n",
            "Requirement already satisfied: google-cloud-spanner in /usr/local/lib/python3.11/dist-packages (3.53.0)\n",
            "Requirement already satisfied: confluent-kafka in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.28 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.28)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.30)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api) (8.6.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (2.4.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.14.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (1.26.1)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.5.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (5.29.4)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner) (0.15.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.69.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (1.71.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api) (3.21.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.70.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (3.11.15)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (2.1.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.6.7)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (2.11.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index) (0.9.0)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.17)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.18.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.7.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.9)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.28->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy requests redis neo4j faiss-cpu torch transformers scikit-learn llama-index hdbscan opentelemetry-api google-cloud-spanner confluent-kafka\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfBlDj0mVngM",
        "outputId": "158631f8-c871-404f-a4cb-9a87280e1198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timezonefinder\n",
            "  Downloading timezonefinder-6.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux_2_5_x86_64.manylinux1_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cffi<2,>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from timezonefinder) (1.17.1)\n",
            "Collecting h3>4 (from timezonefinder)\n",
            "  Downloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from timezonefinder) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi<2,>=1.15.1->timezonefinder) (2.22)\n",
            "Downloading timezonefinder-6.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux_2_5_x86_64.manylinux1_x86_64.manylinux2014_x86_64.whl (51.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h3-4.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h3, timezonefinder\n",
            "Successfully installed h3-4.2.2 timezonefinder-6.5.9\n"
          ]
        }
      ],
      "source": [
        "!pip install timezonefinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBO-qpkakpNq",
        "outputId": "aa389a51-8d38-427c-b380-388a7d037425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Required column missing in call_records. Available columns: ['Call_ID', 'Sender', 'Receiver', 'Call_Duration', 'Call_Location', 'International_Call', 'Timestamp']\n",
            "Warning: Required column missing in ip_records. Available columns: ['IP_ID', 'Sender', 'Receiver', 'IP_Address', 'VPN_Used', 'Website_Accessed', 'Timestamp']\n",
            "Warning: Required column missing in spy_records. Available columns: ['Spy_ID', 'Sender', 'Receiver', 'Voice_Sample', 'Identified_Speaker', 'Timestamp']\n",
            "Warning: Required column missing in village_data. Available columns: ['Family ID', 'Head Name', 'Family Members', 'Village Name', 'Border Area', 'Suspected Activity']\n",
            "Warning: Required column missing in social_media. Available columns: ['Social_ID', 'User_Name', 'Platform', 'Suspicious_Activity', 'Last_Post_Location']\n",
            "Processed datasets. Identified 100 suspicious individuals. Results saved to suspected_criminals.json.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import uuid\n",
        "\n",
        "# Sample dataset paths (replace with actual paths)\n",
        "dataset_paths = {\n",
        "    \"call_records\": \"/content/call_records.csv\",\n",
        "    \"ip_records\": \"/content/ip_records.csv\",\n",
        "    \"spy_records\": \"/content/spy_records.csv\",\n",
        "    \"criminal_records\": \"/content/criminal_records.csv\",\n",
        "    \"village_data\": \"/content/village_records.csv\",\n",
        "    \"social_media\": \"/content/social_media_records.csv\"\n",
        "}\n",
        "\n",
        "# Define rules for identifying criminals\n",
        "rules = {\n",
        "    \"call_records\": lambda df: df[df[\"call_type\"].str.lower() == \"international\"] if \"call_type\" in df.columns else None,\n",
        "    \"ip_records\": lambda df: df[df[\"activity\"].str.contains(\"dark web|vpn|fishy site\", case=False, na=False)] if \"activity\" in df.columns else None,\n",
        "    \"spy_records\": lambda df: df[df[\"suspicion_score\"] > 0.8] if \"suspicion_score\" in df.columns else None,\n",
        "    \"criminal_records\": lambda df: df,  # Already known criminals\n",
        "    \"village_data\": lambda df: df[df[\"border_crossing\"] == True] if \"border_crossing\" in df.columns else None,\n",
        "    \"social_media\": lambda df: df[df[\"keywords\"].str.contains(\"illegal|suspicious\", case=False, na=False)] if \"keywords\" in df.columns else None\n",
        "}\n",
        "\n",
        "# Function to load datasets dynamically\n",
        "def load_dataset(path):\n",
        "    try:\n",
        "        if path.endswith(\".csv\"):\n",
        "            return pd.read_csv(path)\n",
        "        elif path.endswith(\".json\"):\n",
        "            return pd.read_json(path)\n",
        "        elif path.endswith(\".txt\"):\n",
        "            return pd.read_csv(path, delimiter=\"\\t\", header=None)  # Assuming tab-separated\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {path}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Process datasets and find suspicious individuals\n",
        "suspects = []\n",
        "for dataset, path in dataset_paths.items():\n",
        "    df = load_dataset(path)\n",
        "    if df is not None and dataset in rules:\n",
        "        if df.empty:\n",
        "            print(f\"Warning: {dataset} is empty. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        filtered_df = rules[dataset](df)\n",
        "        if filtered_df is None:\n",
        "            print(f\"Warning: Required column missing in {dataset}. Available columns: {df.columns.tolist()}\")\n",
        "            continue\n",
        "\n",
        "        for _, row in filtered_df.iterrows():\n",
        "            suspect = {\n",
        "                \"log_id\": str(uuid.uuid4()),\n",
        "                \"name\": row.get(\"name\", \"Unknown\"),\n",
        "                \"reason\": f\"Flagged in {dataset.replace('_', ' ').title()} dataset\",\n",
        "                \"dataset_match\": [dataset],\n",
        "                \"risk_score\": round(0.8 + 0.2 * (\"suspicion_score\" in row and row[\"suspicion_score\"]), 2)\n",
        "            }\n",
        "            suspects.append(suspect)\n",
        "\n",
        "# Save results as JSON\n",
        "output_file = \"suspected_criminals.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(suspects, f, indent=4)\n",
        "\n",
        "print(f\"Processed datasets. Identified {len(suspects)} suspicious individuals. Results saved to {output_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAhoItij2kEH",
        "outputId": "ce5f1581-6f9e-4262-a9ba-015bfed4e183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded call_records with columns: ['Call_ID', 'Sender', 'Receiver', 'Call_Duration', 'Call_Location', 'International_Call', 'Timestamp']\n",
            "Loaded ip_records with columns: ['IP_ID', 'Sender', 'Receiver', 'IP_Address', 'VPN_Used', 'Website_Accessed', 'Timestamp']\n",
            "Loaded spy_records with columns: ['Spy_ID', 'Sender', 'Receiver', 'Voice_Sample', 'Identified_Speaker', 'Timestamp']\n",
            "Loaded criminal_records with columns: ['Criminal_ID', 'Name', 'Crime_Type', 'Last_Known_Location', 'Under_Surveillance']\n",
            "Loaded village_data with columns: ['Family ID', 'Head Name', 'Family Members', 'Village Name', 'Border Area', 'Suspected Activity']\n",
            "Loaded social_media with columns: ['Social_ID', 'User_Name', 'Platform', 'Suspicious_Activity', 'Last_Post_Location']\n",
            "Flagged: {'id': '2996495c-87d0-494f-bda1-8910cc46173e', 'name': 'Suraj Thakur', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'ba6ea3d0-de07-4fef-b691-7902ff89f6e5', 'name': 'Arjun Singh', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'ab0b4180-2add-4804-ab0f-d23bdc54e161', 'name': 'Deepak Mehta', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'spy_records', 'social_media'], 'risk_score': 2.6}\n",
            "Flagged: {'id': 'bffa09e1-a391-4323-9a82-29bd2a767985', 'name': 'Salman Shaikh', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'b7ff6041-4696-496a-b0e2-f01fafaf5c54', 'name': 'Pankaj Yadav', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '499bbcfc-159a-4186-ba78-f59a54939096', 'name': 'Imran Khan', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '977d55c7-e230-46e2-8be7-472c13707edb', 'name': 'Amit Verma', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'ca90798b-903a-48a7-b296-c16eb98e27cd', 'name': 'Rahul Gupta', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '02592e80-a394-42d1-8ff2-7922c423eb54', 'name': 'Mohammed Ali', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'spy_records', 'social_media'], 'risk_score': 2.6}\n",
            "Flagged: {'id': '03137e0d-6451-4da3-93b9-413e68286f59', 'name': 'Ravi Sharma', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'ed93bc92-a363-40b1-b3fe-addf85c844f4', 'name': 'Salman Shaikh', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'b95a07e3-1094-4875-abd1-6e45587afff3', 'name': 'Ravi Sharma', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '853b6120-a1f4-4012-aa8f-492bef53bf9a', 'name': 'Arjun Singh', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'f600f6f8-9273-435f-bd1c-6f6cc80baed9', 'name': 'Suraj Thakur', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '92ba0ae2-5c5d-4adb-ba29-95322a5840b6', 'name': 'Mohammed Ali', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'spy_records', 'social_media'], 'risk_score': 2.6}\n",
            "Flagged: {'id': 'be7169ba-3312-46f4-919b-f22d53191905', 'name': 'Imran Khan', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '699fa8f9-b07d-42da-9a51-58fdf53c313a', 'name': 'Amit Verma', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '53659ba8-f6ac-4d4a-ba81-ae316f2245fd', 'name': 'Rahul Gupta', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': 'd94f03f4-6398-4763-90b3-bbe76605d07c', 'name': 'Pankaj Yadav', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Used VPN or accessed suspicious websites. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'ip_records', 'spy_records', 'social_media'], 'risk_score': 3.1}\n",
            "Flagged: {'id': '6443e203-8bdb-4486-9d56-bc6e3b73e4fa', 'name': 'Deepak Mehta', 'reason': 'Not found in village records. Listed in criminal records. HIGH RISK. Made international calls. Mentioned in spy records. Suspicious activity detected on social media. ', 'dataset_match': ['criminal_records', 'call_records', 'spy_records', 'social_media'], 'risk_score': 2.6}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import uuid\n",
        "\n",
        "# Sample dataset paths (replace with actual paths)\n",
        "dataset_paths = {\n",
        "    \"call_records\": \"/content/call_records.csv\",\n",
        "    \"ip_records\": \"/content/ip_records.csv\",\n",
        "    \"spy_records\": \"/content/spy_records.csv\",\n",
        "    \"criminal_records\": \"/content/criminal_records.csv\",\n",
        "    \"village_data\": \"/content/village_records.csv\",\n",
        "    \"social_media\": \"/content/social_media_records.csv\"\n",
        "}\n",
        "\n",
        "# Function to load datasets dynamically\n",
        "def load_dataset(path):\n",
        "    if path.endswith(\".csv\"):\n",
        "        return pd.read_csv(path)\n",
        "    elif path.endswith(\".json\"):\n",
        "        return pd.read_json(path)\n",
        "    elif path.endswith(\".txt\"):\n",
        "        return pd.read_csv(path, delimiter=\"\\t\", header=None)  # Assuming tab-separated\n",
        "    return None\n",
        "\n",
        "# Load all datasets\n",
        "datasets = {}\n",
        "for key, path in dataset_paths.items():\n",
        "    df = load_dataset(path)\n",
        "    if df is not None:\n",
        "        datasets[key] = df\n",
        "        print(f\"Loaded {key} with columns: {df.columns.tolist()}\")  # Debugging column names\n",
        "\n",
        "# Function to determine if a person is a suspect\n",
        "def investigate_person(person_name):\n",
        "    suspect = {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"name\": person_name,\n",
        "        \"reason\": \"\",\n",
        "        \"dataset_match\": [],\n",
        "        \"risk_score\": 0.0\n",
        "    }\n",
        "\n",
        "    # Check if the person is in the village data\n",
        "    village_df = datasets.get(\"village_data\", pd.DataFrame())\n",
        "    in_village = village_df[village_df[\"Head Name\"].str.contains(person_name, na=False, case=False)]\n",
        "    if in_village.empty:\n",
        "        suspect[\"reason\"] += \"Not found in village records. \"\n",
        "        suspect[\"risk_score\"] += 0.2\n",
        "    else:\n",
        "        suspect[\"reason\"] += \"Found in village records. \"\n",
        "        suspect[\"dataset_match\"].append(\"village_data\")\n",
        "\n",
        "    # Check if the person is in the criminal records\n",
        "    criminal_df = datasets.get(\"criminal_records\", pd.DataFrame())\n",
        "    in_criminal = criminal_df[criminal_df[\"Name\"].str.contains(person_name, na=False, case=False)]\n",
        "    if not in_criminal.empty:\n",
        "        suspect[\"reason\"] += \"Listed in criminal records. HIGH RISK. \"\n",
        "        suspect[\"dataset_match\"].append(\"criminal_records\")\n",
        "        suspect[\"risk_score\"] += 1.0  # Highest risk\n",
        "\n",
        "    # Check call records for international calls\n",
        "    call_df = datasets.get(\"call_records\", pd.DataFrame())\n",
        "    if not call_df.empty and \"Sender\" in call_df.columns:\n",
        "        calls_made = call_df[(call_df[\"Sender\"] == person_name) & (call_df[\"International_Call\"] == \"Yes\")]\n",
        "        if not calls_made.empty:\n",
        "            suspect[\"reason\"] += \"Made international calls. \"\n",
        "            suspect[\"dataset_match\"].append(\"call_records\")\n",
        "            suspect[\"risk_score\"] += 0.3\n",
        "\n",
        "    # Check IP records for suspicious activity\n",
        "    ip_df = datasets.get(\"ip_records\", pd.DataFrame())\n",
        "    if not ip_df.empty and \"Sender\" in ip_df.columns:\n",
        "        ip_usage = ip_df[(ip_df[\"Sender\"] == person_name) & (ip_df[\"VPN_Used\"] == \"Yes\")]\n",
        "        if not ip_usage.empty:\n",
        "            suspect[\"reason\"] += \"Used VPN or accessed suspicious websites. \"\n",
        "            suspect[\"dataset_match\"].append(\"ip_records\")\n",
        "            suspect[\"risk_score\"] += 0.5\n",
        "\n",
        "    # Check spy records for suspicious communication\n",
        "    spy_df = datasets.get(\"spy_records\", pd.DataFrame())\n",
        "    if not spy_df.empty and \"Sender\" in spy_df.columns:\n",
        "        spy_mentions = spy_df[spy_df[\"Sender\"] == person_name]\n",
        "        if not spy_mentions.empty:\n",
        "            suspect[\"reason\"] += \"Mentioned in spy records. \"\n",
        "            suspect[\"dataset_match\"].append(\"spy_records\")\n",
        "            suspect[\"risk_score\"] += 0.7\n",
        "\n",
        "    # Check social media activity\n",
        "    social_df = datasets.get(\"social_media\", pd.DataFrame())\n",
        "    if not social_df.empty and \"User_Name\" in social_df.columns:\n",
        "        suspicious_posts = social_df[(social_df[\"User_Name\"] == person_name) & (social_df[\"Suspicious_Activity\"].notna())]\n",
        "        if not suspicious_posts.empty:\n",
        "            suspect[\"reason\"] += \"Suspicious activity detected on social media. \"\n",
        "            suspect[\"dataset_match\"].append(\"social_media\")\n",
        "            suspect[\"risk_score\"] += 0.4\n",
        "\n",
        "    # Final decision\n",
        "    if suspect[\"risk_score\"] > 0:\n",
        "        return suspect\n",
        "    return None\n",
        "\n",
        "# Identifying suspects from all datasets\n",
        "suspects = []\n",
        "for key, df in datasets.items():\n",
        "    name_column = next((col for col in df.columns if \"name\" in col.lower() or \"sender\" in col.lower()), None)\n",
        "    if name_column:\n",
        "        for person_name in df[name_column].dropna().unique():\n",
        "            suspect = investigate_person(person_name)\n",
        "            if suspect:\n",
        "                suspects.append(suspect)\n",
        "                print(f\"Flagged: {suspect}\")  # Debugging flagged individuals\n",
        "\n",
        "# Save results as JSON\n",
        "output_file = \"suspected_criminals.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(suspects, f, indent=4)\n",
        "\n",
        "print(f\"Processed datasets. Identified {len(suspects)} suspicious individuals. Results saved to {output_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IErGdAWNHjUV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import uuid\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample dataset paths (replace with actual paths)\n",
        "dataset_paths = {\n",
        "    \"call_records\": \"/content/call_records.csv\",\n",
        "    \"ip_records\": \"/content/ip_records.csv\",\n",
        "    \"spy_records\": \"/content/spy_records.csv\",\n",
        "    \"criminal_records\": \"/content/criminal_records.csv\",\n",
        "    \"village_data\": \"/content/village_records.csv\",\n",
        "    \"social_media\": \"/content/social_media_records.csv\"\n",
        "}\n",
        "\n",
        "# Function to load datasets dynamically\n",
        "def load_dataset(path):\n",
        "    if path.endswith(\".csv\"):\n",
        "        return pd.read_csv(path)\n",
        "    elif path.endswith(\".json\"):\n",
        "        return pd.read_json(path)\n",
        "    elif path.endswith(\".txt\"):\n",
        "        return pd.read_csv(path, delimiter=\"\\t\", header=None)  # Assuming tab-separated\n",
        "    return None\n",
        "\n",
        "# Load all datasets\n",
        "datasets = {}\n",
        "for key, path in dataset_paths.items():\n",
        "    df = load_dataset(path)\n",
        "    if df is not None:\n",
        "        datasets[key] = df\n",
        "        print(f\"Loaded {key} with columns: {df.columns.tolist()}\")  # Debugging column names\n",
        "\n",
        "# Function to determine if a person is a suspect\n",
        "def investigate_person(person_name):\n",
        "    suspect = {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"name\": person_name,\n",
        "        \"reason\": \"\",\n",
        "        \"dataset_match\": [],\n",
        "        \"risk_score\": 0.0\n",
        "    }\n",
        "\n",
        "    # Check if the person is in the village data\n",
        "    village_df = datasets.get(\"village_data\", pd.DataFrame())\n",
        "    in_village = village_df[village_df[\"Head Name\"].str.contains(person_name, na=False, case=False)]\n",
        "    if in_village.empty:\n",
        "        suspect[\"reason\"] += \"Not found in village records. \"\n",
        "        suspect[\"risk_score\"] += 0.2\n",
        "    else:\n",
        "        count = len(in_village)\n",
        "        suspect[\"reason\"] += f\"Found {count} times in village records. \"\n",
        "        suspect[\"dataset_match\"].append(\"village_data\")\n",
        "        suspect[\"risk_score\"] += 0.2 * count\n",
        "\n",
        "    # Check if the person is in the criminal records\n",
        "    criminal_df = datasets.get(\"criminal_records\", pd.DataFrame())\n",
        "    in_criminal = criminal_df[criminal_df[\"Name\"].str.contains(person_name, na=False, case=False)]\n",
        "    if not in_criminal.empty:\n",
        "        count = len(in_criminal)\n",
        "        suspect[\"reason\"] += f\"Listed {count} times in criminal records. HIGH RISK. \"\n",
        "        suspect[\"dataset_match\"].append(\"criminal_records\")\n",
        "        suspect[\"risk_score\"] += 1.0 * count  # Highest risk\n",
        "\n",
        "    # Check call records for international calls\n",
        "    call_df = datasets.get(\"call_records\", pd.DataFrame())\n",
        "    if not call_df.empty and \"Sender\" in call_df.columns:\n",
        "        calls_made = call_df[(call_df[\"Sender\"] == person_name) & (call_df[\"International_Call\"] == \"Yes\")]\n",
        "        if not calls_made.empty:\n",
        "            count = len(calls_made)\n",
        "            suspect[\"reason\"] += f\"Made {count} international calls. \"\n",
        "            suspect[\"dataset_match\"].append(\"call_records\")\n",
        "            suspect[\"risk_score\"] += 0.3 * count\n",
        "\n",
        "    # Check IP records for suspicious activity\n",
        "    ip_df = datasets.get(\"ip_records\", pd.DataFrame())\n",
        "    if not ip_df.empty and \"Sender\" in ip_df.columns:\n",
        "        ip_usage = ip_df[(ip_df[\"Sender\"] == person_name) & (ip_df[\"VPN_Used\"] == \"Yes\")]\n",
        "        if not ip_usage.empty:\n",
        "            count = len(ip_usage)\n",
        "            suspect[\"reason\"] += f\"Used VPN or accessed suspicious websites {count} times. \"\n",
        "            suspect[\"dataset_match\"].append(\"ip_records\")\n",
        "            suspect[\"risk_score\"] += 0.5 * count\n",
        "\n",
        "    # Check spy records for suspicious communication\n",
        "    spy_df = datasets.get(\"spy_records\", pd.DataFrame())\n",
        "    if not spy_df.empty and \"Sender\" in spy_df.columns:\n",
        "        spy_mentions = spy_df[spy_df[\"Sender\"] == person_name]\n",
        "        if not spy_mentions.empty:\n",
        "            count = len(spy_mentions)\n",
        "            suspect[\"reason\"] += f\"Mentioned {count} times in spy records. \"\n",
        "            suspect[\"dataset_match\"].append(\"spy_records\")\n",
        "            suspect[\"risk_score\"] += 0.7 * count\n",
        "\n",
        "    # Check social media activity\n",
        "    social_df = datasets.get(\"social_media\", pd.DataFrame())\n",
        "    if not social_df.empty and \"User_Name\" in social_df.columns:\n",
        "        suspicious_posts = social_df[(social_df[\"User_Name\"] == person_name) & (social_df[\"Suspicious_Activity\"] == \"Yes\")]\n",
        "        if not suspicious_posts.empty:\n",
        "            count = len(suspicious_posts)\n",
        "            suspect[\"reason\"] += f\"Suspicious activity detected {count} times on social media. \"\n",
        "            suspect[\"dataset_match\"].append(\"social_media\")\n",
        "            suspect[\"risk_score\"] += 0.4 * count\n",
        "\n",
        "    return suspect\n",
        "\n",
        "# Identifying suspects from all datasets\n",
        "suspects = defaultdict(lambda: {\"risk_score\": 0, \"reasons\": []})\n",
        "for key, df in datasets.items():\n",
        "    name_column = next((col for col in df.columns if \"name\" in col.lower() or \"sender\" in col.lower()), None)\n",
        "    if name_column:\n",
        "        for person_name in df[name_column].dropna().unique():\n",
        "            suspect = investigate_person(person_name)\n",
        "            if suspect[\"risk_score\"] > 0:\n",
        "                suspects[person_name][\"risk_score\"] += suspect[\"risk_score\"]\n",
        "                suspects[person_name][\"reasons\"].append(suspect[\"reason\"])\n",
        "\n",
        "# Convert to list and sort by risk score\n",
        "sorted_suspects = sorted(\n",
        "    [{\"name\": k, \"risk_score\": v[\"risk_score\"], \"reasons\": v[\"reasons\"]} for k, v in suspects.items()],\n",
        "    key=lambda x: x[\"risk_score\"],\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "# Save results as JSON\n",
        "output_file = \"suspected_criminals_ranked.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(sorted_suspects, f, indent=4)\n",
        "\n",
        "print(f\"Processed datasets. Identified {len(sorted_suspects)} suspicious individuals. Results saved to {output_file}.\")\n",
        "\n",
        "# Print top 10 suspects\n",
        "print(\"\\nTop 10 Suspects:\")\n",
        "for i, suspect in enumerate(sorted_suspects[:10], 1):\n",
        "    print(f\"{i}. {suspect['name']} - Risk Score: {suspect['risk_score']:.2f}\")\n",
        "    print(f\"   Reasons: {' '.join(suspect['reasons'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCb7uLyOHn2I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "call_records = pd.read_csv(\"call_records.csv\")\n",
        "ip_records = pd.read_csv(\"ip_records.csv\")\n",
        "spy_records = pd.read_csv(\"spy_records.csv\")\n",
        "criminal_records = pd.read_csv(\"criminal_records.csv\")\n",
        "village_data = pd.read_csv(\"village_records.csv\")\n",
        "social_media = pd.read_csv(\"social_media_records.csv\")\n",
        "financial_records = pd.read_csv(\"financial_records.csv\")\n",
        "travel_history = pd.read_csv(\"travel_history.csv\")\n",
        "gps_records = pd.read_csv(\"gps_records.csv\")\n",
        "\n",
        "# Get the unique set of people from relevant columns in all datasets\n",
        "people = set()\n",
        "\n",
        "# Datasets with \"Sender\" and \"Receiver\" columns (communication data)\n",
        "communication_datasets = {\n",
        "    \"call_records\": (call_records, \"Sender\", \"Receiver\"),\n",
        "    \"ip_records\": (ip_records, \"Sender\", \"Receiver\"),\n",
        "    \"spy_records\": (spy_records, \"Sender\", \"Receiver\")\n",
        "}\n",
        "\n",
        "# Iterate through the communication datasets to extract people\n",
        "for dataset_name, (df, sender_col, receiver_col) in communication_datasets.items():\n",
        "    people.update(df[sender_col].unique())\n",
        "    people.update(df[receiver_col].unique())\n",
        "\n",
        "# Datasets with only one name column\n",
        "single_name_datasets = {\n",
        "    \"criminal_records\": (criminal_records, \"Name\"),\n",
        "    \"financial_records\": (financial_records, \"Person_Name\"),\n",
        "    \"travel_history\": (travel_history, \"Person_Name\"),\n",
        "    \"gps_records\": (gps_records, \"Person_Name\")\n",
        "}\n",
        "\n",
        "# Iterate through the single name datasets to extract people\n",
        "for dataset_name, (df, name_col) in single_name_datasets.items():\n",
        "    people.update(df[name_col].unique())\n",
        "\n",
        "# Create a dictionary to store relationships\n",
        "relationships = {person: {} for person in people}\n",
        "\n",
        "# Function to find relationships in communication datasets\n",
        "def find_communication_relationships(relationships, df, sender_col, receiver_col, dataset_name):\n",
        "    for index, row in df.iterrows():\n",
        "        sender = row[sender_col]\n",
        "        receiver = row[receiver_col]\n",
        "\n",
        "        if sender in relationships and receiver in relationships:\n",
        "            if receiver not in relationships[sender]:\n",
        "                relationships[sender][receiver] = [dataset_name]\n",
        "            else:\n",
        "                relationships[sender][receiver].append(dataset_name)\n",
        "    return relationships\n",
        "\n",
        "# Iterate through communication datasets\n",
        "for dataset_name, (df, sender_col, receiver_col) in communication_datasets.items():\n",
        "    relationships = find_communication_relationships(relationships, df, sender_col, receiver_col, dataset_name)\n",
        "\n",
        "# Print the relationships\n",
        "for person, related_people in relationships.items():\n",
        "    print(f\"Relationships for {person}:\")\n",
        "    for related_person, datasets in related_people.items():\n",
        "        print(f\"  - {related_person}: {', '.join(datasets)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4tclA7p7_XE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load the datasets\n",
        "call_records = pd.read_csv('call_records.csv')\n",
        "ip_records = pd.read_csv('ip_records.csv')\n",
        "\n",
        "# Extract unique individuals from call records and IP records\n",
        "individuals = set(call_records['Sender']).union(set(call_records['Receiver'])).union(\n",
        "    set(ip_records['Sender']).union(set(ip_records['Receiver']))\n",
        ")\n",
        "\n",
        "# Initialize a dictionary to store relationships\n",
        "relationships = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "# Process call records\n",
        "for _, row in call_records.iterrows():\n",
        "    sender = row['Sender']\n",
        "    receiver = row['Receiver']\n",
        "    details = {\n",
        "        'Type': 'Call',\n",
        "        'Duration': row['Call_Duration'],\n",
        "        'Location': row['Call_Location'],\n",
        "        'International': row['International_Call'],\n",
        "        'Timestamp': row['Timestamp']\n",
        "    }\n",
        "    relationships[sender][receiver].append(details)\n",
        "    relationships[receiver][sender].append(details)  # Add reverse relationship\n",
        "\n",
        "# Process IP records\n",
        "for _, row in ip_records.iterrows():\n",
        "    sender = row['Sender']\n",
        "    receiver = row['Receiver']\n",
        "    details = {\n",
        "        'Type': 'IP',\n",
        "        'IP_Address': row['IP_Address'],\n",
        "        'VPN_Used': row['VPN_Used'],\n",
        "        'Website_Accessed': row['Website_Accessed'],\n",
        "        'Timestamp': row['Timestamp']\n",
        "    }\n",
        "    relationships[sender][receiver].append(details)\n",
        "    relationships[receiver][sender].append(details)  # Add reverse relationship\n",
        "\n",
        "# Generate a table of relationships between all individuals\n",
        "relationship_table = []\n",
        "for person in individuals:\n",
        "    for related_person, details in relationships[person].items():\n",
        "        total_calls = sum(1 for d in details if d['Type'] == 'Call')\n",
        "        total_ip_connections = sum(1 for d in details if d['Type'] == 'IP')\n",
        "        relationship_table.append({\n",
        "            'Person': person,\n",
        "            'Related Person': related_person,\n",
        "            'Total Calls': total_calls,\n",
        "            'Total IP Connections': total_ip_connections,\n",
        "            'Details': details\n",
        "        })\n",
        "\n",
        "# Convert the relationship table into a DataFrame for better visualization\n",
        "relationship_df = pd.DataFrame(relationship_table)\n",
        "\n",
        "# Save the relationship table to a CSV file\n",
        "relationship_df.to_csv('relationship_table.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the table\n",
        "print(relationship_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJxbMHKSpPYT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to load dataset dynamically\n",
        "def load_dataset(path):\n",
        "    if path.endswith(\".csv\"):\n",
        "        return pd.read_csv(path)\n",
        "    elif path.endswith(\".json\"):\n",
        "        return pd.read_json(path)\n",
        "    elif path.endswith(\".txt\"):\n",
        "        return pd.read_csv(path, delimiter=\"\\t\", header=None)  # Assuming tab-separated\n",
        "    return None\n",
        "\n",
        "# Path to the social media dataset (replace with actual path)\n",
        "social_media_path = \"/content/updated_social_network_connections.csv\"\n",
        "social_df = load_dataset(social_media_path)\n",
        "\n",
        "# Identify relevant columns dynamically\n",
        "columns = social_df.columns\n",
        "\n",
        "# Find columns that contain user relationship information\n",
        "sender_col = next((col for col in columns if \"sender\" in col.lower() or \"user\" in col.lower()), None)\n",
        "receiver_col = next((col for col in columns if \"receiver\" in col.lower() or \"follower\" in col.lower()), None)\n",
        "\n",
        "if not sender_col or not receiver_col:\n",
        "    raise ValueError(\"Could not detect appropriate sender/receiver columns in the dataset\")\n",
        "\n",
        "# Extract suspect interactions\n",
        "interactions = social_df[[sender_col, receiver_col]].dropna()\n",
        "\n",
        "# Build a directed graph\n",
        "G = nx.DiGraph()\n",
        "for _, row in interactions.iterrows():\n",
        "    sender, receiver = row[sender_col], row[receiver_col]\n",
        "    if G.has_edge(sender, receiver):\n",
        "        G[sender][receiver]['weight'] += 1  # Increase weight for repeated interactions\n",
        "    else:\n",
        "        G.add_edge(sender, receiver, weight=1)\n",
        "\n",
        "# Identify strong connections\n",
        "threshold = 3  # Define a threshold for frequent interactions\n",
        "strong_connections = [(u, v, d['weight']) for u, v, d in G.edges(data=True) if d['weight'] >= threshold]\n",
        "\n",
        "# Label relationships\n",
        "relationships = []\n",
        "for u, v, weight in strong_connections:\n",
        "    relation_type = \"Middleman\" if nx.has_path(G, v, u) else \"Right-hand Man\"\n",
        "    relationships.append({\n",
        "        \"Suspect\": u,\n",
        "        \"Connected To\": v,\n",
        "        \"Interaction Count\": weight,\n",
        "        \"Relationship\": relation_type\n",
        "    })\n",
        "\n",
        "# Save relationships to a JSON file\n",
        "output_file = \"suspect_relationships.json\"\n",
        "pd.DataFrame(relationships).to_json(output_file, orient=\"records\", indent=4)\n",
        "\n",
        "# Visualize the network\n",
        "def plot_network(graph):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    pos = nx.spring_layout(graph)\n",
        "    weights = [graph[u][v]['weight'] for u, v in graph.edges()]\n",
        "    nx.draw(graph, pos, with_labels=True, node_size=2000, node_color=\"skyblue\", edge_color=weights, width=2.0, cmap=plt.cm.Blues)\n",
        "    plt.title(\"Suspect Interactions Network\")\n",
        "    plt.show()\n",
        "\n",
        "plot_network(G)\n",
        "\n",
        "print(f\"Identified {len(relationships)} strong relationships. Results saved to {output_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQup3cN80Gwt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"social_media_transactions.csv\"  # Update with the correct path\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Ensure required columns exist\n",
        "def validate_columns(df, required_cols):\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "validate_columns(df, [\"Sender\", \"Receiver\", \"Relationship\", \"Transaction_Count\"])\n",
        "\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add edges to the graph\n",
        "for _, row in df.iterrows():\n",
        "    sender, receiver, relation, count = row[\"Sender\"], row[\"Receiver\"], row[\"Relationship\"], row[\"Transaction_Count\"]\n",
        "    G.add_edge(sender, receiver, relationship=relation, weight=count)\n",
        "\n",
        "# Analyze relationships\n",
        "def analyze_relationships(graph):\n",
        "    suspect_network = {}\n",
        "\n",
        "    for suspect in graph.nodes:\n",
        "        connections = list(graph[suspect])  # Get outgoing connections\n",
        "        suspect_network[suspect] = {\n",
        "            \"total_connections\": len(connections),\n",
        "            \"connections\": []\n",
        "        }\n",
        "\n",
        "        for conn in connections:\n",
        "            edge_data = graph[suspect][conn]\n",
        "            suspect_network[suspect][\"connections\"].append({\n",
        "                \"name\": conn,\n",
        "                \"relationship\": edge_data[\"relationship\"],\n",
        "                \"interaction_count\": edge_data[\"weight\"]\n",
        "            })\n",
        "\n",
        "    return suspect_network\n",
        "\n",
        "suspect_relations = analyze_relationships(G)\n",
        "\n",
        "# Save results as JSON\n",
        "output_file = \"suspect_network.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(suspect_relations, f, indent=4)\n",
        "\n",
        "print(f\"Processed dataset. Relationship network saved to {output_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "290-uPqW7y2H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"social_media_suspects.csv\")\n",
        "\n",
        "# Create a graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes (Users)\n",
        "for user in df[\"User\"].unique():\n",
        "    G.add_node(user)\n",
        "\n",
        "# Add edges (Relationships based on interactions)\n",
        "for _, row in df.iterrows():\n",
        "    user = row[\"User\"]\n",
        "    following = row[\"Following\"]\n",
        "    interaction_count = row[\"Interaction_Count\"]\n",
        "    activity = row[\"Activity_Type\"]\n",
        "\n",
        "    # Define relationship strength based on interaction count\n",
        "    if interaction_count > 30:\n",
        "        relation = \"Right-hand man\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        relation = \"Middleman\"\n",
        "    else:\n",
        "        relation = \"Weak Connection\"\n",
        "\n",
        "    # Add edge with attributes\n",
        "    G.add_edge(user, following, weight=interaction_count, relationship=relation, activity=activity)\n",
        "\n",
        "# Generate relationship report\n",
        "relationships = []\n",
        "for u, v, data in G.edges(data=True):\n",
        "    relationships.append({\n",
        "        \"Suspect\": u,\n",
        "        \"Connected_To\": v,\n",
        "        \"Relationship\": data[\"relationship\"],\n",
        "        \"Interaction_Count\": data[\"weight\"],\n",
        "        \"Activity\": data[\"activity\"]\n",
        "    })\n",
        "\n",
        "# Save relationships as JSON\n",
        "output_file = \"social_media_relationships.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(relationships, f, indent=4)\n",
        "\n",
        "print(f\"Relationship analysis saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4llE2bsS8yvN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"social_media_suspects.csv\")\n",
        "\n",
        "# Create a graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes (Users)\n",
        "for user in df[\"User\"].unique():\n",
        "    G.add_node(user)\n",
        "\n",
        "# Add edges (Relationships based on interactions)\n",
        "for _, row in df.iterrows():\n",
        "    user = row[\"User\"]\n",
        "    following = row[\"Following\"]\n",
        "    interaction_count = row[\"Interaction_Count\"]\n",
        "    activity = row[\"Activity_Type\"]\n",
        "\n",
        "    # Define relationship strength based on interaction count\n",
        "    if interaction_count > 30:\n",
        "        relation = \"Right-hand man\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        relation = \"Middleman\"\n",
        "    else:\n",
        "        relation = \"Weak Connection\"\n",
        "\n",
        "    # Add edge with attributes\n",
        "    G.add_edge(user, following, weight=interaction_count, relationship=relation, activity=activity)\n",
        "\n",
        "# Generate relationship report\n",
        "relationships = []\n",
        "for u, v, data in G.edges(data=True):\n",
        "    relationships.append({\n",
        "        \"Suspect\": u,\n",
        "        \"Connected_To\": v,\n",
        "        \"Relationship\": data[\"relationship\"],\n",
        "        \"Interaction_Count\": data[\"weight\"],\n",
        "        \"Activity\": data[\"activity\"]\n",
        "    })\n",
        "\n",
        "# Save relationships as JSON\n",
        "output_json = \"social_media_relationships.json\"\n",
        "with open(output_json, \"w\") as f:\n",
        "    json.dump(relationships, f, indent=4)\n",
        "\n",
        "# Save relationships as CSV\n",
        "output_csv = \"social_media_relationships.csv\"\n",
        "pd.DataFrame(relationships).to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Relationship analysis saved to {output_json} and {output_csv}\")\n",
        "\n",
        "# Draw the graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", edge_color=\"gray\", font_size=8, node_size=1500)\n",
        "plt.title(\"Social Media Suspect Network\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Viep-P7_LfY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Clean column names to remove extra spaces\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Print columns for debugging\n",
        "print(\"Dataset Columns:\", df.columns)\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15\n",
        "}\n",
        "\n",
        "# Create a graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes (Users)\n",
        "for user in df[\"User\"].unique():\n",
        "    G.add_node(user)\n",
        "\n",
        "# Add edges (Relationships based on interactions and scoring system)\n",
        "for _, row in df.iterrows():\n",
        "    user = row[\"User\"]\n",
        "    followings = row[\"Following\"].split(\", \") if isinstance(row[\"Following\"], str) else []\n",
        "\n",
        "    # Corrected column names\n",
        "    interaction_count = row[\"Interaction_Count\"]  # Updated column name\n",
        "    activity = row[\"Activity_Type\"]  # Updated column name\n",
        "    score = interaction_count * activity_scores.get(activity, 1)  # Calculate score\n",
        "\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            G.add_edge(user, following, weight=score, activity=activity)\n",
        "\n",
        "# Generate relationship report\n",
        "relationships = []\n",
        "for u, v, data in G.edges(data=True):\n",
        "    relationships.append({\n",
        "        \"Suspect\": u,\n",
        "        \"Connected_To\": v,\n",
        "        \"Score\": data[\"weight\"],\n",
        "        \"Activity\": data[\"activity\"]\n",
        "    })\n",
        "\n",
        "# Save relationships as JSON\n",
        "json_output_file = \"social_media_relationships.json\"\n",
        "with open(json_output_file, \"w\") as f:\n",
        "    json.dump(relationships, f, indent=4)\n",
        "\n",
        "# Save relationships as CSV\n",
        "csv_output_file = \"social_media_relationships.csv\"\n",
        "pd.DataFrame(relationships).to_csv(csv_output_file, index=False)\n",
        "\n",
        "# Draw network graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=2000, font_size=8)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): data['weight'] for u, v, data in G.edges(data=True)}, font_size=6)\n",
        "plt.title(\"Criminal Social Media Relationship Network\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Relationship analysis saved to {json_output_file} and {csv_output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53m8nlGT_92p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15\n",
        "}\n",
        "\n",
        "# Create a graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes (Users)\n",
        "for user in df[\"User\"].unique():\n",
        "    G.add_node(user)\n",
        "\n",
        "# Add edges (Relationships based on interactions and scoring system)\n",
        "role_mapping = {}\n",
        "for _, row in df.iterrows():\n",
        "    user = row[\"User\"]\n",
        "    followings = row[\"Following\"].split(\", \") if isinstance(row[\"Following\"], str) else []\n",
        "    interaction_count = row[\"Interaction_Count\"]\n",
        "    activity = row[\"Activity_Type\"]\n",
        "    score = interaction_count * activity_scores.get(activity, 1)  # Calculate score\n",
        "\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            G.add_edge(user, following, weight=score, activity=activity)\n",
        "\n",
        "    # Assign roles based on interaction count\n",
        "    if interaction_count > 30:\n",
        "        role_mapping[user] = \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        role_mapping[user] = \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        role_mapping[user] = \"Middleman\"\n",
        "    else:\n",
        "        role_mapping[user] = \"Weak Link\"\n",
        "\n",
        "# Generate relationship report\n",
        "relationships = []\n",
        "for u, v, data in G.edges(data=True):\n",
        "    relationships.append({\n",
        "        \"Suspect\": u,\n",
        "        \"Connected_To\": v,\n",
        "        \"Score\": data[\"weight\"],\n",
        "        \"Activity\": data[\"activity\"],\n",
        "        \"Role\": role_mapping.get(u, \"Unknown\")\n",
        "    })\n",
        "\n",
        "# Save relationships as JSON\n",
        "json_output_file = \"social_media_relationships.json\"\n",
        "with open(json_output_file, \"w\") as f:\n",
        "    json.dump(relationships, f, indent=4)\n",
        "\n",
        "# Save relationships as CSV\n",
        "csv_output_file = \"social_media_relationships.csv\"\n",
        "pd.DataFrame(relationships).to_csv(csv_output_file, index=False)\n",
        "\n",
        "# Draw network graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "# Assign colors based on role\n",
        "node_colors = []\n",
        "for node in G.nodes():\n",
        "    role = role_mapping.get(node, \"Weak Link\")\n",
        "    if role == \"Leader\":\n",
        "        node_colors.append(\"red\")\n",
        "    elif role == \"Right-hand Man\":\n",
        "        node_colors.append(\"blue\")\n",
        "    elif role == \"Middleman\":\n",
        "        node_colors.append(\"green\")\n",
        "    else:\n",
        "        node_colors.append(\"gray\")\n",
        "\n",
        "nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='gray', node_size=2000, font_size=8)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): data['weight'] for u, v, data in G.edges(data=True)}, font_size=6)\n",
        "plt.title(\"Criminal Relationship Network\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Relationship analysis saved to {json_output_file} and {csv_output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKZgfRvUa7vQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Clean column names to remove extra spaces\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to visualize the hierarchy of connections for a specific person\n",
        "def visualize_hierarchy(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Add the main person as a node\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "\n",
        "    # Get their following list and interaction details\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "    activity_type = person_row[\"Activity_Type\"]\n",
        "\n",
        "    # Calculate score for each connection\n",
        "    score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "\n",
        "    # Add edges for followings\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Recursively add connections for each following (2nd level hierarchy)\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            second_level_activity_type = following_row[\"Activity_Type\"]\n",
        "            second_level_score = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    G.add_edge(following, second_following, weight=second_level_score, activity=second_level_activity_type)\n",
        "\n",
        "    # Draw the graph\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "    # Draw nodes and edges\n",
        "    nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (weights/scores)\n",
        "    edge_labels = {(u, v): f\"{data['weight']} ({data['activity']})\" for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
        "\n",
        "    plt.title(f\"Hierarchy of Connections for {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the person to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5eYjQOtdcQo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy and sub-connections for a specific person\n",
        "def visualize_hierarchy(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Add the main person as a node\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "    activity_type = person_row[\"Activity_Type\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for followings (first-level connections)\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            second_level_activity_type = following_row[\"Activity_Type\"]\n",
        "\n",
        "            # Assign role to the first-level connection\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            # Add edge between main person and first-level connection\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections)\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    third_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "\n",
        "                    # Assign role to the second-level connection\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    # Draw the graph with proper coloring based on roles\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='gray', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (weights/scores)\n",
        "    edge_labels = {(u, v): f\"{data['weight']} ({data['activity']})\" for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
        "\n",
        "    plt.title(f\"Hierarchy of Connections for {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1JPDssHhUAS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Prepare data for clustering\n",
        "def prepare_data(df):\n",
        "    # Create a mapping for users and their connections\n",
        "    users = df[\"User\"].unique()\n",
        "    user_indices = {user: idx for idx, user in enumerate(users)}\n",
        "\n",
        "    # Create a distance matrix based on connections\n",
        "    n = len(users)\n",
        "    distance_matrix = np.zeros((n, n))\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        user_idx = user_indices[row[\"User\"]]\n",
        "        followings = row[\"Following\"].split(\", \") if isinstance(row[\"Following\"], str) else []\n",
        "\n",
        "        for following in followings:\n",
        "            if following in user_indices:\n",
        "                following_idx = user_indices[following]\n",
        "                distance_matrix[user_idx, following_idx] = 1  # Assign connection strength\n",
        "\n",
        "    return users, distance_matrix\n",
        "\n",
        "users, distance_matrix = prepare_data(df)\n",
        "\n",
        "# Perform hierarchical clustering using SciPy's linkage method\n",
        "linkage_matrix = linkage(distance_matrix, method=\"ward\")\n",
        "\n",
        "# Plot dendrogram\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(linkage_matrix, labels=users, orientation=\"top\", leaf_rotation=90, leaf_font_size=10)\n",
        "plt.title(\"Hierarchical Clustering of Criminal Connections\")\n",
        "plt.xlabel(\"Users\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SRp5DohitTz"
      },
      "outputs": [],
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACmviSh8iROc"
      },
      "outputs": [],
      "source": [
        "!pip install pygraphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17ckvAm6iKAF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy in a tree-like structure\n",
        "def visualize_hierarchy_tree(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "\n",
        "            # Assign role to first-level connections\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            G.add_edge(person_name, following)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections)\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "\n",
        "                    # Assign role to second-level connections\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    G.add_edge(following, second_following)\n",
        "\n",
        "    # Draw the graph using a hierarchical layout\n",
        "    pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")  # Use Graphviz's dot layout for hierarchy\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy_tree(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itm_Axnh8uzd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "import json\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"Load the dataset and ensure required columns exist.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Check for required columns\n",
        "    expected_columns = ['User', 'Platform', 'Followers', 'Following', 'Interaction_Count', 'Activity_Type']\n",
        "    missing_cols = [col for col in expected_columns if col not in df.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns in dataset: {missing_cols}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def build_network(df):\n",
        "    \"\"\"Construct a network graph from the dataset.\"\"\"\n",
        "    G = nx.DiGraph()  # Directed graph for hierarchy\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        user = row['User']\n",
        "        followings = str(row['Following']).split(',') if pd.notna(row['Following']) else []\n",
        "\n",
        "        for following in followings:\n",
        "            G.add_edge(user.strip(), following.strip())\n",
        "\n",
        "    return G\n",
        "\n",
        "def assign_roles(df):\n",
        "    \"\"\"Assign roles based on interaction count.\"\"\"\n",
        "    role_mapping = {}\n",
        "    for _, row in df.iterrows():\n",
        "        interaction_count = row['Interaction_Count']\n",
        "        user = row['User']\n",
        "\n",
        "        # Assign roles based on interaction count\n",
        "        if interaction_count > 30:\n",
        "            role_mapping[user] = \"Leader\"\n",
        "        elif 15 <= interaction_count <= 30:\n",
        "            role_mapping[user] = \"Right-hand Man\"\n",
        "        elif 5 <= interaction_count < 15:\n",
        "            role_mapping[user] = \"Middleman\"\n",
        "        else:\n",
        "            role_mapping[user] = \"Weak Link\"\n",
        "\n",
        "    return role_mapping\n",
        "\n",
        "def visualize_hierarchy(G, target_user, role_mapping):\n",
        "    \"\"\"Visualize the hierarchical structure.\"\"\"\n",
        "    if target_user not in G:\n",
        "        raise ValueError(f\"User '{target_user}' not found in dataset.\")\n",
        "\n",
        "    # Extract the ego graph (hierarchy of connections)\n",
        "    hierarchy = nx.ego_graph(G, target_user, radius=2)\n",
        "\n",
        "    # Use Graphviz's dot layout for hierarchical visualization\n",
        "    pos = graphviz_layout(hierarchy, prog=\"dot\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in hierarchy.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    # Draw the graph\n",
        "    nx.draw(hierarchy, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=10)\n",
        "\n",
        "    plt.title(f\"Hierarchical View of {target_user}\")\n",
        "    plt.show()\n",
        "\n",
        "def save_hierarchy_json(G, target_user, output_path):\n",
        "    \"\"\"Save the hierarchical structure as JSON.\"\"\"\n",
        "    hierarchy = nx.ego_graph(G, target_user, radius=2)\n",
        "\n",
        "    hierarchy_data = {\n",
        "        'target_user': target_user,\n",
        "        'connections': list(hierarchy.edges)\n",
        "    }\n",
        "\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(hierarchy_data, f, indent=4)\n",
        "\n",
        "    print(f\"Hierarchy saved to {output_path}\")\n",
        "\n",
        "# Main Execution\n",
        "file_path = \"/content/criminal_social_media_dataset.csv\"\n",
        "target_user = \"Amit Verma\"  # Change to desired user\n",
        "output_json = \"hierarchy_output.json\"\n",
        "\n",
        "df = load_dataset(file_path)\n",
        "G = build_network(df)\n",
        "role_mapping = assign_roles(df)\n",
        "visualize_hierarchy(G, target_user, role_mapping)\n",
        "save_hierarchy_json(G, target_user, output_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K6OgmT89bZt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "import json\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"Load the dataset and ensure required columns exist.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Check for required columns\n",
        "    expected_columns = ['User', 'Platform', 'Followers', 'Following', 'Interaction_Count', 'Activity_Type']\n",
        "    missing_cols = [col for col in expected_columns if col not in df.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns in dataset: {missing_cols}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def build_network(df):\n",
        "    \"\"\"Construct a network graph from the dataset.\"\"\"\n",
        "    G = nx.DiGraph()  # Directed graph for hierarchy\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        user = row['User']\n",
        "        followings = str(row['Following']).split(',') if pd.notna(row['Following']) else []\n",
        "\n",
        "        for following in followings:\n",
        "            G.add_edge(user.strip(), following.strip())\n",
        "\n",
        "    return G\n",
        "\n",
        "def assign_roles(df):\n",
        "    \"\"\"Assign roles based on interaction count.\"\"\"\n",
        "    role_mapping = {}\n",
        "    for _, row in df.iterrows():\n",
        "        interaction_count = row['Interaction_Count']\n",
        "        user = row['User']\n",
        "\n",
        "        # Assign roles based on interaction count\n",
        "        if interaction_count > 30:\n",
        "            role_mapping[user] = \"Leader\"\n",
        "        elif 15 <= interaction_count <= 30:\n",
        "            role_mapping[user] = \"Right-hand Man\"\n",
        "        elif 5 <= interaction_count < 15:\n",
        "            role_mapping[user] = \"Middleman\"\n",
        "        else:\n",
        "            role_mapping[user] = \"Weak Link\"\n",
        "\n",
        "    return role_mapping\n",
        "\n",
        "def visualize_hierarchy_tree(G, target_user, role_mapping):\n",
        "    \"\"\"Visualize the hierarchical structure.\"\"\"\n",
        "    if target_user not in G:\n",
        "        raise ValueError(f\"User '{target_user}' not found in dataset.\")\n",
        "\n",
        "    # Extract the ego graph (hierarchy of connections)\n",
        "    hierarchy = nx.ego_graph(G, target_user, radius=2)  # Radius=2 includes direct and sub-connections\n",
        "\n",
        "    # Use Graphviz's dot layout for hierarchical visualization\n",
        "    pos = graphviz_layout(hierarchy, prog=\"dot\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in hierarchy.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    # Draw the graph\n",
        "    nx.draw(hierarchy, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=10)\n",
        "\n",
        "    plt.title(f\"Hierarchical View of {target_user}\")\n",
        "    plt.show()\n",
        "\n",
        "def save_hierarchy_json(G, target_user, output_path):\n",
        "    \"\"\"Save the hierarchical structure as JSON.\"\"\"\n",
        "    hierarchy = nx.ego_graph(G, target_user, radius=2)\n",
        "\n",
        "    hierarchy_data = {\n",
        "        'target_user': target_user,\n",
        "        'connections': list(hierarchy.edges)\n",
        "    }\n",
        "\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(hierarchy_data, f, indent=4)\n",
        "\n",
        "    print(f\"Hierarchy saved to {output_path}\")\n",
        "\n",
        "# Main Execution\n",
        "file_path = \"/content/criminal_social_media_dataset.csv\"  # Replace with your file path\n",
        "target_user = input(\"Enter the name of the person to visualize their hierarchy: \").strip()\n",
        "output_json = \"hierarchy_output.json\"\n",
        "\n",
        "df = load_dataset(file_path)\n",
        "G = build_network(df)\n",
        "role_mapping = assign_roles(df)\n",
        "visualize_hierarchy_tree(G, target_user, role_mapping)\n",
        "save_hierarchy_json(G, target_user, output_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFCmtyVH-oAl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy in a tree-like structure with activity labels\n",
        "def visualize_hierarchy_tree(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for first-level connections with activity labels\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "\n",
        "            # Assign role to first-level connections\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            G.add_edge(person_name, following, activity=activity_type)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections) with activity labels\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    third_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "\n",
        "                    # Assign role to second-level connections\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    G.add_edge(following, second_following, activity=third_level_activity_type)\n",
        "\n",
        "    # Draw the graph using a hierarchical layout\n",
        "    pos = graphviz_layout(G, prog=\"dot\")  # Use Graphviz's dot layout for hierarchy\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (activity types)\n",
        "    edge_labels = {(u, v): data['activity'] for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy_tree(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_OQprSA4zV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy in a tree-like structure with activity labels\n",
        "def visualize_hierarchy_tree(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for first-level connections with activity labels\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "\n",
        "            # Assign role to first-level connections\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            G.add_edge(person_name, following, activity=activity_type)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections) with activity labels\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    third_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "\n",
        "                    # Assign role to second-level connections\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    G.add_edge(following, second_following, activity=third_level_activity_type)\n",
        "\n",
        "    # Draw the graph using a hierarchical layout\n",
        "    pos = graphviz_layout(G, prog=\"dot\")  # Use Graphviz's dot layout for hierarchy\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (activity types)\n",
        "    edge_labels = {(u, v): data['activity'] for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy_tree(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWBchZQ8B9-K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy in a tree-like structure with activity labels\n",
        "def visualize_hierarchy_tree(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "\n",
        "            # Assign role to first-level connections\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            # Calculate score for first-level connection and add edge\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections)\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    third_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "\n",
        "                    # Assign role to second-level connections\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    # Calculate score for second-level connection and add edge\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(third_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=third_level_activity_type)\n",
        "\n",
        "    # Draw the graph using a hierarchical layout\n",
        "    pos = graphviz_layout(G, prog=\"dot\")  # Use Graphviz's dot layout for hierarchy\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    # Draw nodes and edges\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (activity type and score)\n",
        "    edge_labels = {(u, v): f\"{data['weight']} ({data['activity']})\" for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input for specific persons\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    visualize_hierarchy_tree(person_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cAhBMReDPhc"
      },
      "outputs": [],
      "source": [
        "!pip install tkinter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKnlx1oqC0fT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "from tkinter import Tk, Label, Entry, Button\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to visualize hierarchy in a tree-like structure with activity labels\n",
        "def visualize_hierarchy_tree(person_name):\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Role mapping for coloring nodes\n",
        "    role_mapping = {}\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Assign role to the main person\n",
        "    role_mapping[person_name] = assign_roles(interaction_count)\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            second_level_interaction_count = following_row[\"Interaction_Count\"]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "\n",
        "            # Assign role to first-level connections\n",
        "            role_mapping[following] = assign_roles(second_level_interaction_count)\n",
        "\n",
        "            # Calculate score for first-level connection and add edge\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add edges for second-level connections (sub-connections)\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    third_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    third_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "\n",
        "                    # Assign role to second-level connections\n",
        "                    role_mapping[second_following] = assign_roles(third_level_interaction_count)\n",
        "\n",
        "                    # Calculate score for second-level connection and add edge\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(third_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=third_level_activity_type)\n",
        "\n",
        "    # Draw the graph using a hierarchical layout\n",
        "    pos = graphviz_layout(G, prog=\"dot\")  # Use Graphviz's dot layout for hierarchy\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        role = role_mapping.get(node, \"Weak Link\")\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    # Draw nodes and edges\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (activity type and score)\n",
        "    edge_labels = {(u, v): f\"{data['weight']} ({data['activity']})\" for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to handle input and hide input field after visualization\n",
        "def handle_input():\n",
        "    person_name = entry.get().strip()\n",
        "\n",
        "    if not person_name:\n",
        "        label.config(text=\"Please enter a valid name.\")\n",
        "        return\n",
        "\n",
        "    visualize_hierarchy_tree(person_name)\n",
        "\n",
        "    # Hide input field and button after visualization\n",
        "    entry.pack_forget()\n",
        "    button.pack_forget()\n",
        "    label.config(text=f\"Hierarchy visualization completed for '{person_name}'.\")\n",
        "\n",
        "# Create GUI using tkinter\n",
        "root = Tk()\n",
        "root.title(\"Hierarchy Visualization\")\n",
        "\n",
        "label = Label(root, text=\"Enter suspect's name:\")\n",
        "label.pack(pady=10)\n",
        "\n",
        "entry = Entry(root)\n",
        "entry.pack(pady=5)\n",
        "\n",
        "button = Button(root, text=\"Visualize Hierarchy\", command=handle_input)\n",
        "button.pack(pady=10)\n",
        "\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "fX4SN6vhnIC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to visualize the graph interactively using Plotly\n",
        "def visualize_interactive_hierarchy(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        print(\"No hierarchy to display.\")\n",
        "        return\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_labels = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edge_labels.append(f\"{edge[2]['activity']} ({edge[2]['weight']})\")\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        text=[node for node in G.nodes()],\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color='blue',  # Default color (can be customized based on roles)\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        textfont=dict(size=10),\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    # Add callback for clicking on nodes\n",
        "    fig.update_traces(\n",
        "        marker=dict(size=20),\n",
        "        selector=dict(mode='markers'),\n",
        "        hovertemplate='%{text}<extra></extra>'\n",
        "    )\n",
        "\n",
        "    def click_callback(trace, points, state):\n",
        "        clicked_node = points.customdata[points.point_inds[0]]\n",
        "        print(f\"Clicked on: {clicked_node}\")\n",
        "\n",
        "        # Build and visualize new hierarchy for clicked node\n",
        "        new_hierarchy = build_hierarchy(clicked_node)\n",
        "        visualize_interactive_hierarchy(new_hierarchy)\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# Main loop to allow user input and visualization\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    hierarchy_graph = build_hierarchy(person_name)\n",
        "\n",
        "visualize_interactive_hierarchy(hierarchy_graph)\n"
      ],
      "metadata": {
        "id": "Snr0Sjsil-vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "kLpOTXdD3UW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to visualize the graph using matplotlib\n",
        "def visualize_hierarchy_tree(G, person_name):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        print(\"No hierarchy to display.\")\n",
        "        return\n",
        "\n",
        "    # Use Graphviz's dot layout for hierarchical visualization\n",
        "    pos = graphviz_layout(G, prog=\"dot\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Assign colors based on roles\n",
        "    node_colors = []\n",
        "    for node in G.nodes():\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0] if node in df['User'].values else 0\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    # Draw nodes and edges\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='black', node_size=2000, font_size=8)\n",
        "\n",
        "    # Add edge labels (activity type and score)\n",
        "    edge_labels = {(u, v): f\"{data['weight']} ({data['activity']})\" for u, v, data in G.edges(data=True)}\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
        "\n",
        "    plt.title(f\"Hierarchical Connections of {person_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Main loop to allow user input and dynamic exploration of hierarchies\n",
        "while True:\n",
        "    person_name = input(\"Enter the name of the suspect to visualize their hierarchy (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if person_name.lower() == 'exit':\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    hierarchy_graph = build_hierarchy(person_name)\n",
        "\n",
        "    if hierarchy_graph is not None:\n",
        "        visualize_hierarchy_tree(hierarchy_graph, person_name)\n"
      ],
      "metadata": {
        "id": "RA2EgnsuojVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz libgraphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "EvsjeiJhA9km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to visualize the graph interactively using Plotly\n",
        "def visualize_interactive_hierarchy(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        print(\"No hierarchy to display.\")\n",
        "        return\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n"
      ],
      "metadata": {
        "id": "_csmMwg1qQT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        print(f\"Person '{person_name}' not found in the dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to visualize the graph interactively using Plotly\n",
        "def visualize_interactive_hierarchy(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        print(\"No hierarchy to display.\")\n",
        "        return\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color='blue',  # Default color (can be customized based on roles)\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    def click_callback(trace, points, state):\n",
        "        clicked_node = points.customdata[points.point_inds[0]]\n",
        "        print(f\"Clicked on: {clicked_node}\")\n",
        "\n",
        "        # Build and visualize new hierarchy for clicked node\n",
        "        new_hierarchy = build_hierarchy(clicked_node)\n",
        "        visualize_interactive_hierarchy(new_hierarchy)\n",
        "hierarchy_graph = build_hierarchy(\"Suraj Thakur\")\n",
        "visualize_interactive_hierarchy(hierarchy_graph)\n"
      ],
      "metadata": {
        "id": "S5jDkMzM4q4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash\n"
      ],
      "metadata": {
        "id": "48AIW9eb5TSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "kma5fDNn9uBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color='blue',  # Default color (can be customized based on roles)\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\", debounce=True),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\")],\n",
        ")\n",
        "def update_graph(n_clicks, click_data):\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if not ctx.triggered or n_clicks is None:\n",
        "        return go.Figure()\n",
        "\n",
        "    triggered_id = ctx.triggered[0][\"prop_id\"].split(\".\")[0]\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color='blue',  # Default color (can be customized based on roles)\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\", debounce=True),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\")],\n",
        ")\n",
        "def update_graph(n_clicks, click_data):\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if not ctx.triggered or n_clicks is None:\n",
        "        return go.Figure()\n",
        "\n",
        "    triggered_id = ctx.triggered[0][\"prop_id\"].split(\".\")[0]\n",
        "\n",
        "    if triggered_id == \"submit-button\":\n",
        "        person_name = ctx.states[\"input-person.value\"]\n",
        "        hierarchy_graph = build_hierarchy(person_name) #Corrected this line\n",
        "        return create_figure(hierarchy_graph)\n",
        "    elif triggered_id == \"network-graph\" and click_data:\n",
        "        # Handle click data (if needed)\n",
        "        pass\n",
        "\n",
        "    return go.Figure()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "fG74xUf85QYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color='blue',  # Default color (can be customized based on roles)\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                )  # Corrected indentation\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"input-person\", \"value\")],\n",
        ")\n",
        "def update_graph(n_clicks, input_value):\n",
        "    if n_clicks is None:\n",
        "      return create_figure(nx.DiGraph())\n",
        "\n",
        "    person_name = input_value\n",
        "    G = build_hierarchy(person_name)\n",
        "    return create_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "jawSPhqG-BVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "    node_colors = []  # List to store node colors\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "        # Assign colors based on roles\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0]\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=node_colors,  # Use node_colors list for custom colors\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\"),\n",
        "     Input(\"input-person\", \"value\")],\n",
        "     prevent_initial_call=True\n",
        ")\n",
        "def update_graph(n_clicks, click_data, input_person):\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if ctx.triggered[0][\"prop_id\"] == \"submit-button.n_clicks\":\n",
        "        person_name = input_person\n",
        "        G = build_hierarchy(person_name)\n",
        "    elif ctx.triggered[0][\"prop_id\"] == \"network-graph.clickData\":\n",
        "        if click_data is not None:\n",
        "            clicked_node = click_data['points'][0]['customdata'][0]\n",
        "            G = build_hierarchy(clicked_node)\n",
        "        else:\n",
        "            return go.Figure()\n",
        "    else:\n",
        "        return go.Figure()\n",
        "\n",
        "    return create_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "id": "GBDmbRKuFFSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "    node_colors = []  # List to store node colors\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "        # Assign colors based on roles\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0]\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=node_colors,  # Use node_colors list for custom colors\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\"),\n",
        "     Input(\"input-person\", \"value\")],\n",
        "     prevent_initial_call=True\n",
        ")\n",
        "def update_graph(n_clicks, click_data, input_person):\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if ctx.triggered[0][\"prop_id\"] == \"submit-button.n_clicks\":\n",
        "        person_name = input_person\n",
        "        G = build_hierarchy(person_name)\n",
        "    elif ctx.triggered[0][\"prop_id\"] == \"network-graph.clickData\":\n",
        "        if click_data is not None:\n",
        "            clicked_node = click_data['points'][0]['customdata'][0]\n",
        "            G = build_hierarchy(clicked_node)\n",
        "        else:\n",
        "            return go.Figure()\n",
        "    else:\n",
        "        return go.Figure()\n",
        "\n",
        "    return create_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "id": "A7YCJnH4FbWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "    node_colors = []  # List to store node colors\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "        # Assign colors based on roles\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0]\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=node_colors,  # Use node_colors list for custom colors\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\"),\n",
        "     Input(\"input-person\", \"value\")],\n",
        "     prevent_initial_call=True\n",
        ")\n",
        "def update_graph(n_clicks, click_data, input_person):\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if ctx.triggered[0][\"prop_id\"] == \"submit-button.n_clicks\":\n",
        "        person_name = input_person\n",
        "        G = build_hierarchy(person_name)\n",
        "    elif ctx.triggered[0][\"prop_id\"] == \"network-graph.clickData\":\n",
        "        if click_data is not None:\n",
        "            clicked_node = click_data['points'][0]['customdata'][0]\n",
        "            G = build_hierarchy(clicked_node)\n",
        "        else:\n",
        "            return go.Figure()\n",
        "    else:\n",
        "        return go.Figure()\n",
        "\n",
        "    return create_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "id": "ywCwf3HvGtXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for the graph\n",
        "def create_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    pos = nx.spring_layout(G)  # Layout for nodes\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "    node_colors = []  # List to store node colors\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "        # Assign colors based on roles\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0]\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=node_colors,  # Use node_colors list for custom colors\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Interactive Hierarchical Network\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\")],\n",
        "     [Input(\"input-person\", \"value\")]\n",
        ")\n",
        "def update_graph(n_clicks, click_data, input_person):\n",
        "\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if not ctx.triggered or n_clicks is None and click_data is None:\n",
        "        return go.Figure()\n",
        "\n",
        "    triggered_id = ctx.triggered[0][\"prop_id\"]\n",
        "\n",
        "    if triggered_id == \"submit-button.n_clicks\" and input_person:\n",
        "        G = build_hierarchy(input_person)\n",
        "\n",
        "    elif triggered_id == \"network-graph.clickData\" and click_data is not None:\n",
        "        clicked_node = click_data['points'][0]['customdata']\n",
        "        G = build_hierarchy(clicked_node)\n",
        "\n",
        "    else:\n",
        "        return go.Figure()\n",
        "\n",
        "    return create_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "id": "qq4OcrqQMjTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"criminal_social_media_dataset.csv\")\n",
        "\n",
        "# Scoring system based on activity type\n",
        "activity_scores = {\n",
        "    \"Coordinating criminal activities\": 10,\n",
        "    \"Spreading misinformation\": 7,\n",
        "    \"Influencing normal people\": 5,\n",
        "    \"Dark web transactions\": 12,\n",
        "    \"Illegal trade communication\": 15,\n",
        "    \"Recruiting Members\": 8,\n",
        "    \"Fake News\": 6,\n",
        "    \"Illegal Transactions\": 10,\n",
        "    \"Suspicious Posting\": 4\n",
        "}\n",
        "\n",
        "# Function to assign roles based on interaction count\n",
        "def assign_roles(interaction_count):\n",
        "    if interaction_count > 30:\n",
        "        return \"Leader\"\n",
        "    elif 15 <= interaction_count <= 30:\n",
        "        return \"Right-hand Man\"\n",
        "    elif 5 <= interaction_count < 15:\n",
        "        return \"Middleman\"\n",
        "    else:\n",
        "        return \"Weak Link\"\n",
        "\n",
        "# Function to build a directed graph for a given person\n",
        "def build_hierarchy(person_name):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Check if the person exists in the dataset\n",
        "    if person_name not in df[\"User\"].values:\n",
        "        return None\n",
        "\n",
        "    # Add the main person to the graph\n",
        "    G.add_node(person_name)\n",
        "\n",
        "    # Get the row for the main person\n",
        "    person_row = df[df[\"User\"] == person_name].iloc[0]\n",
        "    followings = person_row[\"Following\"].split(\", \") if isinstance(person_row[\"Following\"], str) else []\n",
        "    interaction_count = person_row[\"Interaction_Count\"]\n",
        "\n",
        "    # Add edges for first-level connections\n",
        "    for following in followings:\n",
        "        if following in df[\"User\"].values:\n",
        "            following_row = df[df[\"User\"] == following].iloc[0]\n",
        "            activity_type = following_row[\"Activity_Type\"]\n",
        "            score = interaction_count * activity_scores.get(activity_type, 1)\n",
        "            G.add_edge(person_name, following, weight=score, activity=activity_type)\n",
        "\n",
        "            # Add second-level connections (sub-connections)\n",
        "            second_level_followings = following_row[\"Following\"].split(\", \") if isinstance(following_row[\"Following\"], str) else []\n",
        "            for second_following in second_level_followings:\n",
        "                if second_following in df[\"User\"].values:\n",
        "                    second_level_interaction_count = df[df[\"User\"] == second_following][\"Interaction_Count\"].values[0]\n",
        "                    second_level_activity_type = df[df[\"User\"] == second_following][\"Activity_Type\"].values[0]\n",
        "                    score_second_level = second_level_interaction_count * activity_scores.get(second_level_activity_type, 1)\n",
        "                    G.add_edge(following, second_following, weight=score_second_level, activity=second_level_activity_type)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Function to create a Plotly figure for hierarchical visualization using Graphviz's dot layout\n",
        "def create_hierarchical_figure(G):\n",
        "    if G is None or len(G.nodes) == 0:\n",
        "        return go.Figure()\n",
        "\n",
        "    # Use Graphviz's dot layout for hierarchical visualization\n",
        "    pos = graphviz_layout(G, prog=\"dot\")\n",
        "\n",
        "    # Extract edge data for visualization\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x,\n",
        "        y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    # Extract node data for visualization\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "\n",
        "    node_text = []\n",
        "    node_colors = []  # List to store node colors\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        role_text = f\"Role: {assign_roles(df[df['User'] == node]['Interaction_Count'].values[0])}\"\n",
        "\n",
        "        node_text.append(f\"{node}<br>{role_text}\")\n",
        "\n",
        "        # Assign colors based on roles\n",
        "        interaction_count = df[df['User'] == node]['Interaction_Count'].values[0]\n",
        "        role = assign_roles(interaction_count)\n",
        "        if role == \"Leader\":\n",
        "            node_colors.append(\"red\")\n",
        "        elif role == \"Right-hand Man\":\n",
        "            node_colors.append(\"blue\")\n",
        "        elif role == \"Middleman\":\n",
        "            node_colors.append(\"green\")\n",
        "        else:\n",
        "            node_colors.append(\"gray\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x,\n",
        "        y=node_y,\n",
        "        mode='markers+text',\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=node_colors,  # Use node_colors list for custom colors\n",
        "            line_width=2),\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        customdata=list(G.nodes())  # Attach node names as custom data for interactivity\n",
        "    )\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title=\"Hierarchical Network Visualization\",\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[\n",
        "                            dict(\n",
        "                                text=\"Click on a node to explore its hierarchy\",\n",
        "                                showarrow=False,\n",
        "                                xref=\"paper\",\n",
        "                                yref=\"paper\",\n",
        "                                x=0.5,\n",
        "                                y=-0.1,\n",
        "                                font=dict(size=12)\n",
        "                            )\n",
        "                        ]\n",
        "                    ))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Div([\n",
        "        html.Label(\"Enter suspect's name:\"),\n",
        "        dcc.Input(id=\"input-person\", type=\"text\", placeholder=\"Enter name\"),\n",
        "        html.Button(\"Submit\", id=\"submit-button\"),\n",
        "    ]),\n",
        "\n",
        "    dcc.Graph(id=\"network-graph\")\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"network-graph\", \"figure\"),\n",
        "    [Input(\"submit-button\", \"n_clicks\"),\n",
        "     Input(\"network-graph\", \"clickData\")],\n",
        "     [Input(\"input-person\", \"value\")]\n",
        ")\n",
        "def update_graph(n_clicks, click_data, input_person):\n",
        "\n",
        "    ctx = dash.callback_context\n",
        "\n",
        "    if not ctx.triggered or n_clicks is None and click_data is None:\n",
        "        return go.Figure()\n",
        "\n",
        "    triggered_id = ctx.triggered[0][\"prop_id\"]\n",
        "\n",
        "    if triggered_id == \"submit-button.n_clicks\" and input_person:\n",
        "        G = build_hierarchy(input_person)\n",
        "\n",
        "    elif triggered_id == \"network-graph.clickData\" and click_data is not None:\n",
        "        clicked_node = click_data['points'][0]['customdata']\n",
        "        G = build_hierarchy(clicked_node)\n",
        "\n",
        "    else:\n",
        "        return go.Figure()\n",
        "\n",
        "    return create_hierarchical_figure(G)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)\n"
      ],
      "metadata": {
        "id": "Fh1Y6KV_M8Wq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}